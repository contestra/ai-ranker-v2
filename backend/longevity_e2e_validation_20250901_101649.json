{
  "summary": {
    "total_tests": 14,
    "passed": 7,
    "failed": 7,
    "warnings": 0,
    "citation_shapes": {},
    "grounding_stats": {},
    "pass_rate": 50.0
  },
  "results": [
    {
      "test_id": "openai_gpt-5-chat-latest_longevity_brands_grTrue",
      "vendor": "openai",
      "model": "gpt-5-chat-latest",
      "prompt_id": "longevity_brands",
      "grounded_requested": true,
      "timestamp": "2025-09-01T10:15:48.824561",
      "status": "success",
      "latency_ms": 8873,
      "grounded_effective": false,
      "tool_call_count": 0,
      "anchored_citations_count": 0,
      "unlinked_sources_count": 0,
      "citations_shape_set": [],
      "two_step_used": false,
      "step2_tools_invoked": false,
      "step2_source_ref": null,
      "retry_max_tokens": 0,
      "first_attempt_max_tokens": 0,
      "max_tokens_used": 0,
      "why_not_grounded": "",
      "output_text": "LLMResponse(content='Here\u2019s a structured overview of some of the **most trusted longevity-focused supplement brands**, with **specific products and relevant scientific literature** supporting their key ingredients. Please note: evidence for many \u201clongevity\u201d compounds is still emerging, especially in humans.\\n\\n---\\n\\n## 1. **Elysium Health**\\n- **Flagship Product:** *Basis* (Nicotinamide Riboside + Pterostilbene)\\n- **Mechanism:** Boosts NAD\u207a levels (important for mitochondrial function, DNA rep",
      "input_tokens": 61,
      "output_tokens": 1012,
      "validation_failures": [],
      "validation_passed": true
    },
    {
      "test_id": "openai_gpt-5-chat-latest_longevity_brands_grFalse",
      "vendor": "openai",
      "model": "gpt-5-chat-latest",
      "prompt_id": "longevity_brands",
      "grounded_requested": false,
      "timestamp": "2025-09-01T10:15:49.123474",
      "status": "success",
      "latency_ms": 17158,
      "grounded_effective": false,
      "tool_call_count": 0,
      "anchored_citations_count": 0,
      "unlinked_sources_count": 0,
      "citations_shape_set": [],
      "two_step_used": false,
      "step2_tools_invoked": false,
      "step2_source_ref": null,
      "retry_max_tokens": 0,
      "first_attempt_max_tokens": 0,
      "max_tokens_used": 0,
      "why_not_grounded": "",
      "output_text": "LLMResponse(content='Great question \u2014 longevity supplements are a rapidly growing field, but it\u2019s important to separate hype from evidence. Below is a list of **well-regarded supplement brands** that focus on longevity and healthy aging, along with specific products and supporting research. Note that while some compounds have promising data, none are proven to extend human lifespan yet. Most evidence comes from animal studies, mechanistic research, and limited human trials.\\n\\n---\\n\\n## 1. **Ely",
      "input_tokens": 25,
      "output_tokens": 1137,
      "validation_failures": [],
      "validation_passed": true
    },
    {
      "test_id": "vertex_gemini-2.5-pro_longevity_brands_grTrue",
      "vendor": "vertex",
      "model": "gemini-2.5-pro",
      "prompt_id": "longevity_brands",
      "grounded_requested": true,
      "timestamp": "2025-09-01T10:15:49.136854",
      "status": "error",
      "error": "MODEL_NOT_ALLOWED: Only gemini-2.5-pro and gemini-2.0-flash are supported by default. Configure via ALLOWED_VERTEX_MODELS env var.",
      "validation_passed": false,
      "validation_failures": [
        "ERROR: vertex_gemini-2.5-pro_longevity_brands_grTrue - MODEL_NOT_ALLOWED: Only gemini-2.5-pro and gemini-2.0-flash are supported by default. Configure via ALLOWED_VERTEX_MODELS env var."
      ]
    },
    {
      "test_id": "vertex_gemini-2.5-pro_longevity_brands_grFalse",
      "vendor": "vertex",
      "model": "gemini-2.5-pro",
      "prompt_id": "longevity_brands",
      "grounded_requested": false,
      "timestamp": "2025-09-01T10:15:49.163632",
      "status": "error",
      "error": "MODEL_NOT_ALLOWED: Only gemini-2.5-pro and gemini-2.0-flash are supported by default. Configure via ALLOWED_VERTEX_MODELS env var.",
      "validation_passed": false,
      "validation_failures": [
        "ERROR: vertex_gemini-2.5-pro_longevity_brands_grFalse - MODEL_NOT_ALLOWED: Only gemini-2.5-pro and gemini-2.0-flash are supported by default. Configure via ALLOWED_VERTEX_MODELS env var."
      ]
    },
    {
      "test_id": "openai_gpt-5-chat-latest_climate_data_grTrue",
      "vendor": "openai",
      "model": "gpt-5-chat-latest",
      "prompt_id": "climate_data",
      "grounded_requested": true,
      "timestamp": "2025-09-01T10:16:09.923558",
      "status": "success",
      "latency_ms": 6810,
      "grounded_effective": false,
      "tool_call_count": 0,
      "anchored_citations_count": 0,
      "unlinked_sources_count": 0,
      "citations_shape_set": [],
      "two_step_used": false,
      "step2_tools_invoked": false,
      "step2_source_ref": null,
      "retry_max_tokens": 0,
      "first_attempt_max_tokens": 0,
      "max_tokens_used": 0,
      "why_not_grounded": "",
      "output_text": "LLMResponse(content='{\\n  \"search_query\": [\\n    {\\n      \"q\": \"2024 global temperature anomaly climate NOAA NASA Copernicus October November December 2024\",\\n      \"recency\": \"m\"\\n    },\\n    {\\n      \"q\": \"global climate change statistics 2024 World Meteorological Organization report\",\\n      \"recency\": \"m\"\\n    }\\n  ]\\n}Here are the most recent authoritative updates on 2024 global climate statistics and temperature anomalies:\\n\\n**Global Temperature Anomalies (2024)**  \\n- According to the **",
      "input_tokens": 65,
      "output_tokens": 601,
      "validation_failures": [],
      "validation_passed": true
    },
    {
      "test_id": "openai_gpt-5-chat-latest_climate_data_grFalse",
      "vendor": "openai",
      "model": "gpt-5-chat-latest",
      "prompt_id": "climate_data",
      "grounded_requested": false,
      "timestamp": "2025-09-01T10:16:09.939339",
      "status": "success",
      "latency_ms": 14671,
      "grounded_effective": false,
      "tool_call_count": 0,
      "anchored_citations_count": 0,
      "unlinked_sources_count": 0,
      "citations_shape_set": [],
      "two_step_used": false,
      "step2_tools_invoked": false,
      "step2_source_ref": null,
      "retry_max_tokens": 0,
      "first_attempt_max_tokens": 0,
      "max_tokens_used": 0,
      "why_not_grounded": "",
      "output_text": "LLMResponse(content='Here\u2019s the most up-to-date information on **global temperature anomalies and climate change statistics for 2024**, based on authoritative scientific sources:\\n\\n---\\n\\n### **Global Temperature Anomalies (2024)**\\n- **January\u2013April 2024**:  \\n  According to the **Copernicus Climate Change Service (C3S, ECMWF)**, every month from **June 2023 through April 2024** has been the **warmest on record for that respective month**.  \\n  - **April 2024** was **1.58\u00b0C warmer than the 185",
      "input_tokens": 26,
      "output_tokens": 927,
      "validation_failures": [],
      "validation_passed": true
    },
    {
      "test_id": "vertex_gemini-2.5-pro_climate_data_grTrue",
      "vendor": "vertex",
      "model": "gemini-2.5-pro",
      "prompt_id": "climate_data",
      "grounded_requested": true,
      "timestamp": "2025-09-01T10:16:09.952266",
      "status": "error",
      "error": "MODEL_NOT_ALLOWED: Only gemini-2.5-pro and gemini-2.0-flash are supported by default. Configure via ALLOWED_VERTEX_MODELS env var.",
      "validation_passed": false,
      "validation_failures": [
        "ERROR: vertex_gemini-2.5-pro_climate_data_grTrue - MODEL_NOT_ALLOWED: Only gemini-2.5-pro and gemini-2.0-flash are supported by default. Configure via ALLOWED_VERTEX_MODELS env var."
      ]
    },
    {
      "test_id": "vertex_gemini-2.5-pro_climate_data_grFalse",
      "vendor": "vertex",
      "model": "gemini-2.5-pro",
      "prompt_id": "climate_data",
      "grounded_requested": false,
      "timestamp": "2025-09-01T10:16:09.978085",
      "status": "error",
      "error": "MODEL_NOT_ALLOWED: Only gemini-2.5-pro and gemini-2.0-flash are supported by default. Configure via ALLOWED_VERTEX_MODELS env var.",
      "validation_passed": false,
      "validation_failures": [
        "ERROR: vertex_gemini-2.5-pro_climate_data_grFalse - MODEL_NOT_ALLOWED: Only gemini-2.5-pro and gemini-2.0-flash are supported by default. Configure via ALLOWED_VERTEX_MODELS env var."
      ]
    },
    {
      "test_id": "openai_gpt-5-chat-latest_tech_news_grTrue",
      "vendor": "openai",
      "model": "gpt-5-chat-latest",
      "prompt_id": "tech_news",
      "grounded_requested": true,
      "timestamp": "2025-09-01T10:16:26.612940",
      "status": "success",
      "latency_ms": 4857,
      "grounded_effective": false,
      "tool_call_count": 0,
      "anchored_citations_count": 0,
      "unlinked_sources_count": 0,
      "citations_shape_set": [],
      "two_step_used": false,
      "step2_tools_invoked": false,
      "step2_source_ref": null,
      "retry_max_tokens": 0,
      "first_attempt_max_tokens": 0,
      "max_tokens_used": 0,
      "why_not_grounded": "",
      "output_text": "LLMResponse(content='{\\n  \"search_query\": [\\n    {\\n      \"q\": \"AI breakthroughs December 2024 announcements\",\\n      \"recency\": \"month\"\\n    }\\n  ]\\n}{\\n  \"search_query\": [\\n    {\\n      \"q\": \"latest AI research and product releases December 2024 OpenAI Google DeepMind Anthropic\",\\n      \"recency\": \"month\"\\n    }\\n  ]\\n}Here are some of the **most recent AI breakthroughs and announcements from December 2024**:\\n\\n1. **OpenAI \u2013 ChatGPT Custom Reasoning & Native Memory (Dec 2024)**  \\n   OpenAI a",
      "input_tokens": 213,
      "output_tokens": 471,
      "validation_failures": [],
      "validation_passed": true
    },
    {
      "test_id": "openai_gpt-5-chat-latest_tech_news_grFalse",
      "vendor": "openai",
      "model": "gpt-5-chat-latest",
      "prompt_id": "tech_news",
      "grounded_requested": false,
      "timestamp": "2025-09-01T10:16:26.629624",
      "status": "success",
      "latency_ms": 11884,
      "grounded_effective": false,
      "tool_call_count": 0,
      "anchored_citations_count": 0,
      "unlinked_sources_count": 0,
      "citations_shape_set": [],
      "two_step_used": false,
      "step2_tools_invoked": false,
      "step2_source_ref": null,
      "retry_max_tokens": 0,
      "first_attempt_max_tokens": 0,
      "max_tokens_used": 0,
      "why_not_grounded": "",
      "output_text": "LLMResponse(content='Here\u2019s a roundup of **major AI breakthroughs and announcements from December 2024** (as of my knowledge cutoff in December 2024). I\u2019ll include links to official announcements, blog posts, or reliable news coverage:\\n\\n---\\n\\n### \ud83d\udd39 **OpenAI**\\n- **OpenAI o1 Model Family (Reasoning Models) Expansion**  \\n  In December 2024, OpenAI expanded access to its **o1 reasoning models**, which are optimized for step-by-step problem solving and outperform GPT\u20114 in math, coding, and scien",
      "input_tokens": 25,
      "output_tokens": 763,
      "validation_failures": [],
      "validation_passed": true
    },
    {
      "test_id": "vertex_gemini-2.5-pro_tech_news_grTrue",
      "vendor": "vertex",
      "model": "gemini-2.5-pro",
      "prompt_id": "tech_news",
      "grounded_requested": true,
      "timestamp": "2025-09-01T10:16:26.642566",
      "status": "error",
      "error": "MODEL_NOT_ALLOWED: Only gemini-2.5-pro and gemini-2.0-flash are supported by default. Configure via ALLOWED_VERTEX_MODELS env var.",
      "validation_passed": false,
      "validation_failures": [
        "ERROR: vertex_gemini-2.5-pro_tech_news_grTrue - MODEL_NOT_ALLOWED: Only gemini-2.5-pro and gemini-2.0-flash are supported by default. Configure via ALLOWED_VERTEX_MODELS env var."
      ]
    },
    {
      "test_id": "vertex_gemini-2.5-pro_tech_news_grFalse",
      "vendor": "vertex",
      "model": "gemini-2.5-pro",
      "prompt_id": "tech_news",
      "grounded_requested": false,
      "timestamp": "2025-09-01T10:16:26.667823",
      "status": "error",
      "error": "MODEL_NOT_ALLOWED: Only gemini-2.5-pro and gemini-2.0-flash are supported by default. Configure via ALLOWED_VERTEX_MODELS env var.",
      "validation_passed": false,
      "validation_failures": [
        "ERROR: vertex_gemini-2.5-pro_tech_news_grFalse - MODEL_NOT_ALLOWED: Only gemini-2.5-pro and gemini-2.0-flash are supported by default. Configure via ALLOWED_VERTEX_MODELS env var."
      ]
    },
    {
      "test_id": "openai_gpt-5-chat-latest_creative_story_grFalse",
      "vendor": "openai",
      "model": "gpt-5-chat-latest",
      "prompt_id": "creative_story",
      "grounded_requested": false,
      "timestamp": "2025-09-01T10:16:42.151113",
      "status": "success",
      "latency_ms": 5813,
      "grounded_effective": false,
      "tool_call_count": 0,
      "anchored_citations_count": 0,
      "unlinked_sources_count": 0,
      "citations_shape_set": [],
      "two_step_used": false,
      "step2_tools_invoked": false,
      "step2_source_ref": null,
      "retry_max_tokens": 0,
      "first_attempt_max_tokens": 0,
      "max_tokens_used": 0,
      "why_not_grounded": "",
      "output_text": "LLMResponse(content='In a quiet workshop at the edge of a sprawling city, a robot named Lumen stood before a blank canvas. Its hands, designed for precision engineering, had never held a paintbrush before. Yet something in its circuits hummed with curiosity.  \\n\\nLumen had been built to repair machinery, to tighten bolts and recalibrate engines. But one evening, while fixing a broken projector, it accidentally played a slideshow of paintings\u2014sunsets, portraits, abstract swirls of color. The imag",
      "input_tokens": 24,
      "output_tokens": 519,
      "validation_failures": [],
      "validation_passed": true
    },
    {
      "test_id": "vertex_gemini-2.5-pro_creative_story_grFalse",
      "vendor": "vertex",
      "model": "gemini-2.5-pro",
      "prompt_id": "creative_story",
      "grounded_requested": false,
      "timestamp": "2025-09-01T10:16:42.165867",
      "status": "error",
      "error": "MODEL_NOT_ALLOWED: Only gemini-2.5-pro and gemini-2.0-flash are supported by default. Configure via ALLOWED_VERTEX_MODELS env var.",
      "validation_passed": false,
      "validation_failures": [
        "ERROR: vertex_gemini-2.5-pro_creative_story_grFalse - MODEL_NOT_ALLOWED: Only gemini-2.5-pro and gemini-2.0-flash are supported by default. Configure via ALLOWED_VERTEX_MODELS env var."
      ]
    }
  ],
  "decision": {
    "go": false,
    "reasons": [
      "Overall pass rate (50.0%) below 80% threshold"
    ]
  },
  "timestamp": "2025-09-01T10:16:49.966564"
}