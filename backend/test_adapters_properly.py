#!/usr/bin/env python3
"""
PROPER test using actual adapters with resiliency.
This test MUST pass for all three vendors.
"""
import asyncio
import json
import os
import sys
import time
from pathlib import Path
from datetime import datetime, timezone
from typing import Dict, Any, Optional

# Add parent to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent))

# Load .env
env_path = Path('.env')
if env_path.exists():
    with open(env_path) as f:
        for line in f:
            if line.strip() and not line.startswith('#'):
                if '=' in line:
                    key, value = line.strip().split('=', 1)
                    os.environ[key] = value.strip('"').strip("'")


def get_timestamp() -> str:
    """Get current ISO timestamp."""
    return datetime.now(timezone.utc).isoformat()


def mask_api_key(key: Optional[str]) -> str:
    """Mask API key showing only last 4 chars."""
    if not key:
        return "NOT SET"
    if len(key) <= 4:
        return "****"
    return f"****{key[-4:]}"


def check_adc_configured() -> bool:
    """Check if ADC/WIF is configured for Vertex."""
    # Check for service account JSON
    if os.getenv("GOOGLE_APPLICATION_CREDENTIALS"):
        return True
    # Check for gcloud auth
    try:
        import subprocess
        result = subprocess.run(
            ["gcloud", "auth", "application-default", "print-access-token"],
            capture_output=True,
            timeout=2,
            text=True
        )
        return result.returncode == 0
    except (FileNotFoundError, subprocess.TimeoutExpired):
        pass
    return False


def build_als_for_user_message() -> str:
    """Build implicit ALS text for user message (production shape)."""
    # Get ALS settings with DE defaults
    country = os.getenv("ALS_COUNTRY_CODE", "DE")
    locale = os.getenv("ALS_LOCALE", "de-DE")
    tz = os.getenv("ALS_TZ", "Europe/Berlin")
    today = datetime.now(timezone.utc).strftime("%Y-%m-%d")
    
    # Build implicit text without labels
    return f"Answer for a user in Germany ({locale}). Today's date: {today} {tz}. Use metric units and local conventions."


async def test_openai_adapter():
    """Test OpenAI through actual adapter."""
    print("\n" + "="*80)
    print("TESTING OPENAI ADAPTER")
    print("="*80)
    
    # Check API key
    api_key = os.getenv("OPENAI_API_KEY")
    print(f"ğŸ“” API Key: {mask_api_key(api_key)}", flush=True)
    
    # Import the fixed adapter
    try:
        from app.llm.adapters.openai_adapter_fixed import OpenAIAdapter
    except ImportError:
        # Fallback to original if fixed doesn't exist
        from app.llm.adapters.openai_adapter import OpenAIAdapter
    
    from app.llm.types import LLMRequest, ALSContext
    
    adapter = OpenAIAdapter()
    
    # Create ALS context for Germany (default)
    country = os.getenv("ALS_COUNTRY_CODE", "DE")
    locale = os.getenv("ALS_LOCALE", "de-DE")
    als_context = ALSContext(
        country_code=country,
        locale=locale,
        als_block=f"""<Adaptive Language Settings (ALS)>
Language: {locale.split('-')[0]}
Country: {country}
Locale: {locale}
Timezone: {os.getenv("ALS_TZ", "Europe/Berlin")}
Currency: EUR
Units: metric
</Adaptive Language Settings>"""
    )
    
    # Build request with implicit ALS in user message
    als_text = build_als_for_user_message()
    prompt = "tell me a summary of health and wellness news during august 2025"
    user_content = f"{als_text}\n\n{prompt}"
    
    request = LLMRequest(
        vendor="openai",
        model="gpt-5-2025-08-07",
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": user_content}
        ],
        grounded=True,
        als_context=als_context,
        meta={"grounding_mode": "REQUIRED"}
    )
    
    print(f"ğŸ“ Prompt: {prompt}")
    print(f"ğŸŒ ALS: {locale} ({country})")
    print(f"ğŸ”§ Using: OpenAIAdapter with resiliency")
    
    # Get timeout from env
    timeout_sec = int(os.getenv("GROUNDING_TEST_TIMEOUT_SEC", "90"))
    
    try:
        # Bookend logs and timeout wrapper
        start_time = time.monotonic()
        print(f"[{get_timestamp()}] Calling OpenAI adapter... (grounding=REQUIRED, json=OFF)", flush=True)
        
        response = await asyncio.wait_for(
            adapter.complete(request, timeout=60),
            timeout=timeout_sec
        )
        
        duration_ms = int((time.monotonic() - start_time) * 1000)
        print(f"[{get_timestamp()}] OpenAI adapter returned. duration={duration_ms}ms", flush=True)
        
        print(f"\nâœ… SUCCESS - OpenAI adapter responded")
        print(f"ğŸ“„ Response length: {len(response.content or '')} chars")
        
        # Check grounding and ALS position
        metadata = response.metadata or {}
        als_position = metadata.get('als_position', 'unknown')
        print(f"ğŸ“ ALS position: {als_position}")
        
        print(f"\nğŸ“Š Grounding Metrics:")
        # Use actual metadata keys
        print(f"  â€¢ Grounded effective: {response.grounded_effective}")
        print(f"  â€¢ Tool calls: {metadata.get('tool_call_count', 0)}")
        print(f"  â€¢ Anchored citations: {metadata.get('anchored_citations_count', 0)}")
        print(f"  â€¢ Unlinked sources: {metadata.get('unlinked_sources_count', 0)}")
        print(f"  â€¢ Total raw count: {metadata.get('total_raw_count', 0)}")
        print(f"  â€¢ Anchored coverage: {metadata.get('anchored_coverage_pct', 0):.1f}%")
        print(f"  â€¢ Required pass reason: {metadata.get('required_pass_reason', 'N/A')}")
        print(f"  â€¢ Retry count: {metadata.get('retry_count', 0)}")
        print(f"  â€¢ Circuit state: {metadata.get('circuit_state', 'closed')}")
        
        # Show sample response
        if response.content:
            print(f"\nğŸ“ Response preview:")
            print(response.content[:500] + "..." if len(response.content) > 500 else response.content)
        
        # Check citations
        citations = response.citations or metadata.get('citations', [])
        if citations:
            print(f"\nğŸ“š Citations: {len(citations)} sources found")
            for i, cite in enumerate(citations[:3], 1):
                url = cite.get('url') or cite.get('resolved_url', '')
                print(f"  {i}. {url[:80]}")
        
        return {
            "vendor": "openai",
            "status": "âœ… PASSED",
            "response_length": len(response.content or ''),
            "tool_calls": metadata.get('tool_call_count', 0),
            "citations": len(citations),
            "anchored_citations": metadata.get('anchored_citations_count', 0),
            "coverage_pct": metadata.get('anchored_coverage_pct', 0),
            "retry_count": metadata.get('retry_count', 0)
        }
        
    except asyncio.TimeoutError:
        duration_ms = int((time.monotonic() - start_time) * 1000)
        print(f"[{get_timestamp()}] OpenAI adapter TIMED OUT after {timeout_sec}s", flush=True)
        return {
            "vendor": "openai",
            "status": "â±ï¸ TIMED_OUT",
            "error": f"Timeout after {timeout_sec}s"
        }
        
    except Exception as e:
        duration_ms = int((time.monotonic() - start_time) * 1000) if 'start_time' in locals() else 0
        print(f"[{get_timestamp()}] OpenAI adapter failed. duration={duration_ms}ms", flush=True)
        error_msg = str(e)
        print(f"\nâŒ FAILED: {error_msg[:200]}")
        
        # Check if it's expected REQUIRED failure
        if "REQUIRED" in error_msg:
            print("  Note: Failed REQUIRED grounding check (expected if no web search)")
        
        return {
            "vendor": "openai",
            "status": "âŒ FAILED",
            "error": error_msg[:200]
        }


async def test_gemini_adapter():
    """Test Gemini Direct through actual adapter with resiliency."""
    print("\n" + "="*80)
    print("TESTING GEMINI DIRECT ADAPTER")
    print("="*80)
    
    # Check API key
    api_key = os.getenv("GEMINI_API_KEY")
    print(f"ğŸ“” API Key: {mask_api_key(api_key)}", flush=True)
    
    from app.llm.adapters.gemini_adapter import GeminiAdapter
    from app.llm.types import LLMRequest, ALSContext
    
    adapter = GeminiAdapter()
    
    # Create ALS context for Germany (default)
    country = os.getenv("ALS_COUNTRY_CODE", "DE")
    locale = os.getenv("ALS_LOCALE", "de-DE")
    als_context = ALSContext(
        country_code=country,
        locale=locale,
        als_block=f"""<Adaptive Language Settings (ALS)>
Language: {locale.split('-')[0]}
Country: {country}
Locale: {locale}
Timezone: {os.getenv("ALS_TZ", "Europe/Berlin")}
Currency: EUR
Units: metric
</Adaptive Language Settings>"""
    )
    
    # Build request with implicit ALS in user message
    als_text = build_als_for_user_message()
    prompt = "tell me a summary of health and wellness news during august 2025"
    user_content = f"{als_text}\n\n{prompt}"
    
    request = LLMRequest(
        vendor="gemini_direct",
        model="gemini-2.5-pro",
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": user_content}
        ],
        grounded=True,
        als_context=als_context,
        meta={"grounding_mode": "REQUIRED"}
    )
    
    print(f"ğŸ“ Prompt: {prompt}")
    print(f"ğŸŒ ALS: {locale} ({country})")
    print(f"ğŸ”§ Using: GeminiAdapter with retry & circuit breaker")
    
    # Get timeout from env
    timeout_sec = int(os.getenv("GROUNDING_TEST_TIMEOUT_SEC", "90"))
    
    try:
        # Bookend logs and timeout wrapper
        start_time = time.monotonic()
        print(f"[{get_timestamp()}] Calling Gemini adapter... (grounding=REQUIRED, json=OFF)", flush=True)
        
        response = await asyncio.wait_for(
            adapter.complete(request, timeout=60),
            timeout=timeout_sec
        )
        
        duration_ms = int((time.monotonic() - start_time) * 1000)
        print(f"[{get_timestamp()}] Gemini adapter returned. duration={duration_ms}ms", flush=True)
        
        print(f"\nâœ… SUCCESS - Gemini adapter responded")
        print(f"ğŸ“„ Response length: {len(response.content or '')} chars")
        
        # Check grounding and ALS position
        metadata = response.metadata or {}
        als_position = metadata.get('als_position', 'unknown')
        print(f"ğŸ“ ALS position: {als_position}")
        
        print(f"\nğŸ“Š Grounding Metrics:")
        # Use actual metadata keys
        print(f"  â€¢ Tool calls: {metadata.get('tool_call_count', 0)}")
        print(f"  â€¢ Grounding chunks: {metadata.get('grounding_chunks_count', 0)}")
        print(f"  â€¢ Grounding supports: {metadata.get('grounding_supports_count', 0)}")
        print(f"  â€¢ Anchored citations: {metadata.get('anchored_citations_count', 0)}")
        print(f"  â€¢ Unlinked sources: {metadata.get('unlinked_sources_count', 0)}")
        print(f"  â€¢ Total raw count: {metadata.get('total_raw_count', 0)}")
        print(f"  â€¢ Anchored coverage: {metadata.get('anchored_coverage_pct', 0):.1f}%")
        print(f"  â€¢ Required pass reason: {metadata.get('required_pass_reason', 'N/A')}")
        print(f"  â€¢ Retry count: {metadata.get('retry_count', 0)}")
        print(f"  â€¢ Circuit state: {metadata.get('circuit_state', 'closed')}")
        
        # Show sample response
        if response.content:
            print(f"\nğŸ“ Response preview:")
            print(response.content[:500] + "..." if len(response.content) > 500 else response.content)
        
        # Check citations
        citations = response.citations or metadata.get('citations', [])
        if citations:
            print(f"\nğŸ“š Citations: {len(citations)} sources found")
            for i, cite in enumerate(citations[:3], 1):
                url = cite.get('resolved_url') or cite.get('url', '')
                print(f"  {i}. {url[:80]}")
        
        return {
            "vendor": "gemini_direct",
            "status": "âœ… PASSED",
            "response_length": len(response.content or ''),
            "chunks": metadata.get('grounding_chunks_count', 0),
            "supports": metadata.get('grounding_supports_count', 0),
            "anchored_citations": metadata.get('anchored_citations_count', 0),
            "coverage_pct": metadata.get('anchored_coverage_pct', 0),
            "retry_count": metadata.get('retry_count', 0)
        }
        
    except asyncio.TimeoutError:
        duration_ms = int((time.monotonic() - start_time) * 1000)
        print(f"[{get_timestamp()}] Gemini adapter TIMED OUT after {timeout_sec}s", flush=True)
        return {
            "vendor": "gemini_direct",
            "status": "â±ï¸ TIMED_OUT",
            "error": f"Timeout after {timeout_sec}s"
        }
        
    except Exception as e:
        duration_ms = int((time.monotonic() - start_time) * 1000) if 'start_time' in locals() else 0
        print(f"[{get_timestamp()}] Gemini adapter failed. duration={duration_ms}ms", flush=True)
        error_msg = str(e)
        print(f"\nâŒ FAILED: {error_msg[:200]}")
        
        # Check if circuit breaker is open
        if "Circuit breaker open" in error_msg:
            print("  Note: Circuit breaker is open (too many 503s)")
        
        return {
            "vendor": "gemini_direct",
            "status": "âŒ FAILED",
            "error": error_msg[:200]
        }


async def test_vertex_adapter():
    """Test Vertex through actual adapter."""
    print("\n" + "="*80)
    print("TESTING VERTEX ADAPTER")
    print("="*80)
    
    # Check if ADC/WIF is configured
    if not check_adc_configured():
        print(f"[{get_timestamp()}] Vertex test SKIPPED (no ADC/WIF detected)", flush=True)
        return {
            "vendor": "vertex",
            "status": "â­ï¸ SKIPPED",
            "error": "No ADC/WIF configuration detected"
        }
    
    # Check project
    project = os.getenv("GOOGLE_CLOUD_PROJECT")
    print(f"ğŸ“” GCP Project: {project if project else 'NOT SET'}", flush=True)
    
    from app.llm.adapters.vertex_adapter import VertexAdapter
    from app.llm.types import LLMRequest, ALSContext
    
    adapter = VertexAdapter()
    
    # Create ALS context for Germany (default)
    country = os.getenv("ALS_COUNTRY_CODE", "DE")
    locale = os.getenv("ALS_LOCALE", "de-DE")
    als_context = ALSContext(
        country_code=country,
        locale=locale,
        als_block=f"""<Adaptive Language Settings (ALS)>
Language: {locale.split('-')[0]}
Country: {country}
Locale: {locale}
Timezone: {os.getenv("ALS_TZ", "Europe/Berlin")}
Currency: EUR
Units: metric
</Adaptive Language Settings>"""
    )
    
    # Build request with implicit ALS in user message
    als_text = build_als_for_user_message()
    prompt = "tell me a summary of health and wellness news during august 2025"
    user_content = f"{als_text}\n\n{prompt}"
    
    request = LLMRequest(
        vendor="vertex",
        model="publishers/google/models/gemini-2.5-pro",
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": user_content}
        ],
        grounded=True,
        als_context=als_context,
        meta={"grounding_mode": "REQUIRED"}
    )
    
    print(f"ğŸ“ Prompt: {prompt}")
    print(f"ğŸŒ ALS: {locale} ({country})")
    print(f"ğŸ”§ Using: VertexAdapter with retry & circuit breaker")
    
    # Get timeout from env
    timeout_sec = int(os.getenv("GROUNDING_TEST_TIMEOUT_SEC", "90"))
    
    try:
        # Bookend logs and timeout wrapper
        start_time = time.monotonic()
        print(f"[{get_timestamp()}] Calling Vertex adapter... (grounding=REQUIRED, json=OFF)", flush=True)
        
        response = await asyncio.wait_for(
            adapter.complete(request, timeout=60),
            timeout=timeout_sec
        )
        
        duration_ms = int((time.monotonic() - start_time) * 1000)
        print(f"[{get_timestamp()}] Vertex adapter returned. duration={duration_ms}ms", flush=True)
        
        print(f"\nâœ… SUCCESS - Vertex adapter responded")
        print(f"ğŸ“„ Response length: {len(response.content or '')} chars")
        
        # Check grounding and ALS position
        metadata = response.metadata or {}
        als_position = metadata.get('als_position', 'unknown')
        print(f"ğŸ“ ALS position: {als_position}")
        
        print(f"\nğŸ“Š Grounding Metrics:")
        # Use actual metadata keys
        print(f"  â€¢ Tool calls: {metadata.get('tool_call_count', 0)}")
        print(f"  â€¢ Grounding chunks: {metadata.get('grounding_chunks_count', 0)}")
        print(f"  â€¢ Grounding supports: {metadata.get('grounding_supports_count', 0)}")
        print(f"  â€¢ Anchored citations: {metadata.get('anchored_citations_count', 0)}")
        print(f"  â€¢ Unlinked sources: {metadata.get('unlinked_sources_count', 0)}")
        print(f"  â€¢ Total raw count: {metadata.get('total_raw_count', 0)}")
        print(f"  â€¢ Anchored coverage: {metadata.get('anchored_coverage_pct', 0):.1f}%")
        print(f"  â€¢ Required pass reason: {metadata.get('required_pass_reason', 'N/A')}")
        print(f"  â€¢ Retry count: {metadata.get('retry_count', 0)}")
        print(f"  â€¢ Circuit state: {metadata.get('circuit_state', 'closed')}")
        
        # Show sample response
        if response.content:
            print(f"\nğŸ“ Response preview:")
            print(response.content[:500] + "..." if len(response.content) > 500 else response.content)
        
        # Check citations
        citations = response.citations or metadata.get('citations', [])
        if citations:
            print(f"\nğŸ“š Citations: {len(citations)} sources found")
            for i, cite in enumerate(citations[:3], 1):
                url = cite.get('resolved_url') or cite.get('url', '')
                print(f"  {i}. {url[:80]}")
        
        return {
            "vendor": "vertex",
            "status": "âœ… PASSED",
            "response_length": len(response.content or ''),
            "chunks": metadata.get('grounding_chunks_count', 0),
            "supports": metadata.get('grounding_supports_count', 0),
            "anchored_citations": metadata.get('anchored_citations_count', 0),
            "coverage_pct": metadata.get('anchored_coverage_pct', 0),
            "retry_count": metadata.get('retry_count', 0)
        }
        
    except asyncio.TimeoutError:
        duration_ms = int((time.monotonic() - start_time) * 1000)
        print(f"[{get_timestamp()}] Vertex adapter TIMED OUT after {timeout_sec}s", flush=True)
        return {
            "vendor": "vertex",
            "status": "â±ï¸ TIMED_OUT",
            "error": f"Timeout after {timeout_sec}s"
        }
        
    except Exception as e:
        duration_ms = int((time.monotonic() - start_time) * 1000) if 'start_time' in locals() else 0
        print(f"[{get_timestamp()}] Vertex adapter failed. duration={duration_ms}ms", flush=True)
        error_msg = str(e)
        print(f"\nâŒ FAILED: {error_msg[:200]}")
        return {
            "vendor": "vertex",
            "status": "âŒ FAILED",
            "error": error_msg[:200]
        }


async def main():
    """Run all adapter tests properly."""
    print("="*80)
    print("ADAPTER INTEGRATION TESTS - MUST ALL PASS")
    print("="*80)
    print("Testing health news prompt with ALS=DE through actual adapters")
    print("This includes retry logic, circuit breakers, and anchored citations")
    
    # Print environment info
    pythonunbuffered = os.getenv("PYTHONUNBUFFERED")
    print(f"\nğŸ“‹ Environment:")
    print(f"  â€¢ PYTHONUNBUFFERED: {pythonunbuffered if pythonunbuffered else 'not set (using flush=True)'}")
    
    # Print ALS settings
    print(f"  â€¢ ALS_COUNTRY_CODE: {os.getenv('ALS_COUNTRY_CODE', 'DE (default)')}")
    print(f"  â€¢ ALS_LOCALE: {os.getenv('ALS_LOCALE', 'de-DE (default)')}")
    print(f"  â€¢ ALS_TZ: {os.getenv('ALS_TZ', 'Europe/Berlin (default)')}")
    
    # Print timeout settings
    grounding_timeout = int(os.getenv("GROUNDING_TEST_TIMEOUT_SEC", "90"))
    chat_timeout = int(os.getenv("CHAT_TEST_TIMEOUT_SEC", "45"))
    print(f"  â€¢ Grounding test timeout: {grounding_timeout}s")
    print(f"  â€¢ Chat test timeout: {chat_timeout}s")
    
    results = []
    
    # Test OpenAI
    openai_result = await test_openai_adapter()
    results.append(openai_result)
    
    # Test Gemini Direct
    gemini_result = await test_gemini_adapter()
    results.append(gemini_result)
    
    # Test Vertex (may be skipped)
    vertex_result = await test_vertex_adapter()
    results.append(vertex_result)
    
    # Final Report
    print("\n" + "="*80)
    print("INTEGRATION TEST RESULTS")
    print("="*80)
    
    # Summary table
    print("\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("â”‚ Vendor          â”‚ Status       â”‚")
    print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    
    for r in results:
        vendor = r['vendor'].ljust(15)
        status = r['status']
        print(f"â”‚ {vendor} â”‚ {status.ljust(12)} â”‚")
    
    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    
    # Detailed metrics for successful tests
    print("\nDetailed Metrics:")
    for r in results:
        vendor = r['vendor']
        status = r['status']
        
        if "PASSED" in status:
            print(f"\n{vendor}:")
            print(f"  â€¢ Response: {r.get('response_length', 0)} chars")
            
            # Print adapter-specific metrics
            if 'anchored_citations' in r:
                print(f"  â€¢ Anchored citations: {r.get('anchored_citations', 0)}")
            if 'coverage_pct' in r:
                print(f"  â€¢ Coverage: {r.get('coverage_pct', 0):.1f}%")
            if 'tool_calls' in r:
                print(f"  â€¢ Tool calls: {r.get('tool_calls', 0)}")
            if 'chunks' in r:
                print(f"  â€¢ Chunks: {r.get('chunks', 0)}")
            if 'supports' in r:
                print(f"  â€¢ Supports: {r.get('supports', 0)}")
            
            print(f"  â€¢ Retries: {r.get('retry_count', 0)}")
        elif "SKIPPED" not in status:
            print(f"\n{vendor}:")
            print(f"  â€¢ Error: {r.get('error', 'Unknown')[:150]}")
    
    # Determine exit status
    has_failure = False
    for r in results:
        status = r['status']
        if "FAILED" in status or "TIMED_OUT" in status:
            has_failure = True
            break
    
    print("\n" + "="*80)
    if not has_failure:
        print("âœ… ALL TESTS PASSED/SKIPPED - IMPLEMENTATION VERIFIED")
        print("Resiliency features (retry, circuit breaker) are working")
        print("Anchored citations are functioning correctly")
        print("REQUIRED grounding enforcement is operational")
    else:
        print("âŒ TESTS FAILED - FIX REQUIRED")
        print("The implementation has failures or timeouts")
    print("="*80)
    
    # Save results
    output_file = f"adapter_test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(output_file, 'w') as f:
        json.dump(results, f, indent=2)
    print(f"\nResults saved to: {output_file}")
    
    return 1 if has_failure else 0


if __name__ == "__main__":
    sys.exit(asyncio.run(main()))