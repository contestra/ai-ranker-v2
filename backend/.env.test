# Test Suite Environment Configuration
# Apply ChatGPT's recommended settings to stabilize tests

# =======================
# OpenAI Rate Limiting
# =======================
# Reduce token budget to avoid 429 errors
OPENAI_MAX_OUTPUT_TOKENS_CAP=2000
OPENAI_DEFAULT_MAX_OUTPUT_TOKENS=1400

# Lower TPM limit below actual 30k for headroom
# This will be read by get_settings() and used by the rate limiter
# You may need to update your settings to read this from env
OPENAI_TPM_LIMIT=24000

# Force sequential execution for tests
OPENAI_MAX_CONCURRENCY=1

# =======================
# Timeout Configuration
# =======================
# Standard timeouts for ungrounded/grounded requests
LLM_TIMEOUT_UN=90
LLM_TIMEOUT_GR=240

# =======================
# Proxy Configuration
# =======================
# Disable Vertex proxy for stability (set in test runner)
# For tests, override vantage_policy for vertex to always use ALS_ONLY

# =======================
# Test Execution Strategy
# =======================
# Recommended test order to minimize rate limit issues:
# 1. Run ungrounded tests first (lower token usage)
# 2. Run grounded tests without proxy
# 3. Run proxy tests last (OpenAI only)
#
# For Vertex: Always use ALS_ONLY (no PROXY_ONLY or ALS_PLUS_PROXY)
# For OpenAI: Limit proxy tests to essential scenarios

# =======================
# Additional Safeguards
# =======================
# If a single call uses >20k tokens, add extra sleep before next test
# Monitor actual token usage vs estimates to tune adaptive multiplier

# =======================
# Circuit Breaker Settings
# =======================
# These control proxy circuit breaker behavior
CIRCUIT_BREAKER_FAILURE_THRESHOLD=3
CIRCUIT_BREAKER_RECOVERY_TIMEOUT=600
CIRCUIT_BREAKER_WINDOW_SIZE=300